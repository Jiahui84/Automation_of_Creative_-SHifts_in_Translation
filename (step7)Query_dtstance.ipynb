{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import needed libraries\n",
    "import gensim\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.models import FastText\n",
    "import numpy as np\n",
    "from numpy import *\n",
    "import scipy\n",
    "from scipy.spatial import distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set a function to turn the text into list with every sentence that tkoenized into words as sublists\n",
    "def getIndex2word(filename):\n",
    "    index2word = []\n",
    "    word2index = []\n",
    "    with open(filename, encoding='utf-8') as fr:\n",
    "        for line in fr:\n",
    "            tmp = {}\n",
    "            newline = line.strip().split()\n",
    "            index2word.append({index:word for index, word in enumerate(newline, 0)})\n",
    "            word2index.append({word:index for index, word in enumerate(newline, 0)})\n",
    "    return index2word, word2index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read the English and Chinese text file\n",
    "zh_index2word, zh_word2index = getIndex2word(\"中文.txt\")\n",
    "en_index2word, en_word2index = getIndex2word(\"英文.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read the results of word alignment, and turn it into a list with every line that tkoenized as sublists\n",
    "def getCDQ():\n",
    "    datas = []\n",
    "    with open('词对齐.txt', encoding='utf-8') as fr:\n",
    "        for line in fr:\n",
    "            datas.append(line.strip().split())\n",
    "    return datas\n",
    "datas = getCDQ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the bilingual mapped Chinese model\n",
    "ZH_model = KeyedVectors.load_word2vec_format(\"TRG_HT_MAPPED.EMB\", binary=False, unicode_errors=\"jgnore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the bilingual mapped English model\n",
    "EN_model = KeyedVectors.load_word2vec_format(\"SRC_HT_MAPPED.EMB\", binary=False, unicode_errors=\"jgnore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set a function to query vector in English model\n",
    "def get_en_vector(word):\n",
    "    vector_en = EN_model.wv.get_vector(word)\n",
    "    return vector_en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set a function to query vector in Chinese model\n",
    "def get_zh_vector(word):\n",
    "    vector_zh = ZH_model.wv.get_vector(word)\n",
    "    return vector_zh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.2307753413915634, 0.715864360332489, 0.8030718713998795, 0.8467187583446503, 1.158906102180481, 0.9721608012914658, 0.8436356484889984, 0.8065491765737534, 1.1719548106193542, 0.8199136853218079, 0.8982102572917938, 0.8401868790388107]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-12-8a3a1addb479>:10: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  if en_word in EN_model.wv.vocab and zh_word in ZH_model.wv.vocab:\n",
      "<ipython-input-9-9ffdebc57d0f>:3: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  vector_en = EN_model.wv.get_vector(word)\n"
     ]
    }
   ],
   "source": [
    "#get the cosine distance of word pairs\n",
    "for index, (d, zh, en) in enumerate(zip(datas, zh_index2word, en_index2word)): \n",
    "    dists = []\n",
    "    skipped = []\n",
    "    for a in d:\n",
    "        en_wid, zh_wid = a.split(\"-\")\n",
    "        en_word = en[int(en_wid)]\n",
    "        zh_word = zh[int(zh_wid)]\n",
    "#         print(en_wid, en_word, zh_wid, zh_word)\n",
    "        if en_word in EN_model.wv.vocab and zh_word in ZH_model.wv.vocab:\n",
    "            w_en_vector = get_en_vector(en_word)\n",
    "            #print(\"en vector:\", w_en_vector)\n",
    "            w_zh_vector = get_zh_vector(zh_word)\n",
    "            #print(\"zh vector:\", w_zh_vector)\n",
    "            distance = (scipy.spatial.distance.cosine(w_en_vector, w_zh_vector))\n",
    "            #print(\"distance:\", distance)\n",
    "            dists.append(distance)\n",
    "        else:\n",
    "            skipped.append(a)\n",
    "print(dists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#automatically select the Source words whose cosine distance of its word pairs are in the setting range (irrational range)\n",
    "def getTarget(alph1, alph2):\n",
    "    Auto_UCP_MT = []\n",
    "    for index, (d, zh, en) in enumerate(zip(datas, zh_index2word, en_index2word)): \n",
    "        dists = []\n",
    "        for a in d:\n",
    "            en_wid, zh_wid = a.split(\"-\")\n",
    "            en_word = en[int(en_wid)]\n",
    "            zh_word = zh[int(zh_wid)]\n",
    "#             print(en_wid, en_word, zh_wid, zh_word)\n",
    "            if en_word in EN_model.wv.vocab and zh_word in ZH_model.wv.vocab:\n",
    "                w_en_vector = get_en_vector(en_word)\n",
    "                #print(\"en vector:\", w_en_vector)\n",
    "                w_zh_vector = get_zh_vector(zh_word)\n",
    "                #print(\"zh vector:\", w_zh_vector)\n",
    "                distance = (scipy.spatial.distance.cosine(w_en_vector, w_zh_vector))\n",
    "                #print(\"distance:\", distance)\n",
    "                if distance>=alph1 and distance<=alph2:\n",
    "                    dists.append(en_word)  \n",
    "            else:\n",
    "                pass\n",
    "        Auto_UCP_MT.append(dists)\n",
    "        print(dists)\n",
    "    return Auto_UCP_MT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pages', 'pages', 'former', 'wore']\n",
      "['eccentricities', 'his', 'claimed', 'deliberate', 'his', 'former', 'media', 'late', 'cultivated']\n",
      "['Metro', '.', 'persona', 'told', 'stop']\n",
      "['spark', 'he', 'conversation', '.', 'put', 'surgical', 'pages']\n",
      "['form', 'you', 'your', 'true', 'what', 'tell', '.', 'own']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-13-2edcdd8b3fcb>:11: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  if en_word in EN_model.wv.vocab and zh_word in ZH_model.wv.vocab:\n",
      "<ipython-input-9-9ffdebc57d0f>:3: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  vector_en = EN_model.wv.get_vector(word)\n"
     ]
    }
   ],
   "source": [
    "#get the words within the setting range per line \n",
    "Auto_UCP_MT = getTarget(0.8, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrtie every line of words in a text; the line is aligns to that in ST \n",
    "with open('写入.txt', 'w') as output_num:\n",
    "    for sublist in Auto_UCP_MT:\n",
    "        for i in sublist:\n",
    "            output_num.write(str(i))\n",
    "            output_num.write(' ')\n",
    "        output_num.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['8', '9'], ['0', '1'], ['1', '2'], ['5'], ['2']]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Below are codes for another function: if I have got the word order of units of creative potential in ST, I can use these word order to get their word pair in TT\n",
    "#first I low the txt containing the word order of units of creative potential in ST\n",
    "targets = []\n",
    "with open('数字.txt', encoding='utf-8') as fr:\n",
    "    for line in fr:\n",
    "        targets.append(line.strip().split(','))\n",
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['3-14',\n",
       "  '0-4',\n",
       "  '10-8',\n",
       "  '1-5',\n",
       "  '10-14',\n",
       "  '13-1',\n",
       "  '12-0',\n",
       "  '0-3',\n",
       "  '11-2',\n",
       "  '7-6',\n",
       "  '2-12',\n",
       "  '6-10',\n",
       "  '9-8',\n",
       "  '9-14'],\n",
       " ['16-20',\n",
       "  '18-20',\n",
       "  '14-16',\n",
       "  '9-11',\n",
       "  '1-3',\n",
       "  '19-21',\n",
       "  '13-14',\n",
       "  '6-8',\n",
       "  '5-6',\n",
       "  '22-22',\n",
       "  '0-1',\n",
       "  '17-17',\n",
       "  '2-4',\n",
       "  '1-2',\n",
       "  '13-15',\n",
       "  '3-5',\n",
       "  '23-23',\n",
       "  '0-0',\n",
       "  '9-12',\n",
       "  '8-10',\n",
       "  '10-13',\n",
       "  '16-14',\n",
       "  '7-8'],\n",
       " ['12-4',\n",
       "  '4-0',\n",
       "  '18-17',\n",
       "  '24-36',\n",
       "  '5-1',\n",
       "  '40-29',\n",
       "  '34-31',\n",
       "  '23-40',\n",
       "  '13-5',\n",
       "  '19-21',\n",
       "  '1-12',\n",
       "  '6-2',\n",
       "  '32-27',\n",
       "  '41-30',\n",
       "  '3-0',\n",
       "  '14-6',\n",
       "  '29-25',\n",
       "  '42-44',\n",
       "  '25-37',\n",
       "  '20-22',\n",
       "  '26-38',\n",
       "  '17-14',\n",
       "  '11-4',\n",
       "  '0-10',\n",
       "  '36-33',\n",
       "  '19-20',\n",
       "  '30-26',\n",
       "  '15-7',\n",
       "  '7-3',\n",
       "  '33-28',\n",
       "  '27-42',\n",
       "  '18-18',\n",
       "  '18-15',\n",
       "  '38-30',\n",
       "  '21-23',\n",
       "  '31-27',\n",
       "  '22-39',\n",
       "  '2-9',\n",
       "  '1-13',\n",
       "  '28-43']]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read the file with word alignment results\n",
    "datas[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set an empty list for word pairs of units of creative potential\n",
    "UCP = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['9-8', '9-14']\n",
      "['0-1', '0-0', '1-3', '1-2']\n",
      "['1-12', '1-13', '2-9']\n",
      "['5-7']\n",
      "['2-3']\n"
     ]
    }
   ],
   "source": [
    "#query the aligned word pair the word order, and turn the word pair in a list per line\n",
    "for tg, das in zip(targets, datas):\n",
    "    tmp = []\n",
    "    for l in tg:\n",
    "        for k in das:\n",
    "            kx = k.split('-')\n",
    "            if l == kx[0]:\n",
    "                tmp.append(k)\n",
    "    print(tmp)\n",
    "    UCP.append(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
